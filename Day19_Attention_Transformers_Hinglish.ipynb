{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf1f Day 19: Attention & Transformers with TensorFlow (Hinglish)\n", "\n", "Aaj hum dekhenge:\n", "- Attention Mechanism kya hota hai?\n", "- Transformer architecture ka overview\n", "- BERT ka use karke ek text classifier banana\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udccc 1\ufe0f\u20e3 Why Attention?\n", "\n", "RNN/CNN me fixed-size context hota hai.\n", "Attention me model har input token ko sab tokens ke sath compare karta hai aur decide karta hai ki kahan focus karna hai.\n", "\n", "Ye NLP & Vision dono me kaam karta hai."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udd16 2\ufe0f\u20e3 Transformer Architecture\n", "\n", "Transformer = Encoder + Decoder + Self-Attention\n", "\n", "- Encoder: Input ko process karta hai\n", "- Decoder: Output generate karta hai\n", "- Self-Attention: Har token apne context me important tokens ko weight deta hai\n", "\n", "Hum yaha sirf Encoder (BERT) use karenge."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd37 3\ufe0f\u20e3 Install & Import Libraries\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import tensorflow_hub as hub\n", "import tensorflow_text as text\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "print(\"TensorFlow:\", tf.__version__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udce5 4\ufe0f\u20e3 Load BERT Preprocessor & Encoder\n", "\n", "Hum yaha `small_bert` use karenge jo fast & accurate hai."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bert_preprocess = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n", "bert_encoder = hub.load(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2\")\n", "\n", "print(\"\u2705 BERT Preprocessor & Encoder loaded\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcdd 5\ufe0f\u20e3 Sample Text & Preprocess\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sample_text = [\"TensorFlow is amazing!\", \"I love learning about transformers.\"]\n", "\n", "text_inputs = tf.constant(sample_text)\n", "encoder_inputs = bert_preprocess(text_inputs)\n", "\n", "print(\"Keys:\", encoder_inputs.keys())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 6\ufe0f\u20e3 Encode Text & See Outputs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outputs = bert_encoder(encoder_inputs)\n", "\n", "# Pooled output \u2192 sentence representation\n", "pooled_output = outputs['pooled_output']\n", "\n", "print(\"Pooled output shape:\", pooled_output.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd17 7\ufe0f\u20e3 Build a Classification Model\n", "\n", "Hum pooled_output ko Dense layers me bhej ke classification karenge."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras import layers, Model\n", "\n", "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n", "preprocessed_text = hub.KerasLayer(bert_preprocess)(text_input)\n", "outputs = hub.KerasLayer(bert_encoder, trainable=True)(preprocessed_text)\n", "\n", "pooled_output = outputs['pooled_output']\n", "dropout = layers.Dropout(0.1)(pooled_output)\n", "classifier = layers.Dense(1, activation='sigmoid')(dropout)\n", "\n", "model = Model(inputs=text_input, outputs=classifier)\n", "\n", "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddea 8\ufe0f\u20e3 Train on Dummy Data (Demo)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Dummy dataset\n", "texts = np.array([\"Good movie\", \"Bad movie\", \"Great film\", \"Terrible film\"])\n", "labels = np.array([1, 0, 1, 0])\n", "\n", "model.fit(texts, labels, epochs=2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd17 Summary Table\n", "\n", "| Step | Description |\n", "|------|-------------|\n", "| Load BERT | Preprocessor & Encoder from TF Hub |\n", "| Preprocess | Text ko tokens me badlo |\n", "| Encode | BERT output nikaalo |\n", "| Classify | Dense layers ke through predict karo |\n", "\n", "---\n", "\ud83c\udf89 Aapne Attention & Transformers ka ek simple text classifier bana liya!"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}